{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ab139e-8dc4-4ce5-ae1f-ce60f425576e",
   "metadata": {},
   "source": [
    "# Fine-Tuning Llama 3.2 1B (Huggingface)\n",
    "- Single GPU Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc1bc04-2582-4f30-a22f-ca5c575289e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') # 경고 메시지를 무시하고 숨기거나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27305ed-5827-4dcd-8930-c8a40f792272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4eff85-7071-47b8-b57a-392f942b8879",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.environ.get('HF_TOKEN',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b48af4-bcde-4be0-bb84-bd761fff6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U peft trl transformers diffusers\n",
    "# !pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df377cc-ee6d-438b-b432-440c5d24e3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 17:16:48.326654: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-14 17:16:48.342650: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-14 17:16:48.347635: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 17:16:48.360003: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "667b8554-a004-4654-8fa0-8e69eabf1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B\"  # Llama 3.2 1B 모델 ID\n",
    "# MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"  # Llama 3.2 1B 모델 ID\n",
    "OUTPUT_DIR = \"./llama-3.2-1b-finetuned\"\n",
    "# DATASET_PATH = \"train.jsonl\"  # 또는 JSONL 파일 경로\n",
    "DATASET_PATH = \"dataset/kogpt/mini_ai_dataset.jsonl\"  # 또는 JSONL 파일 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7914343a-4b72-46bc-b4e0-2d2767f7b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. 학습 파라미터 설정\n",
    "max_seq_length = 512\n",
    "\n",
    "training_params = {\n",
    "    \"learning_rate\": 2e-5,\n",
    "    # \"max_seq_length\": 512,\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"per_device_train_batch_size\": 1, #<--- 배치를 높이면, Memroy 부족으로 OOM이 발생합니다. \n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"optim\": \"adamw_torch\",\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"logging_steps\": 100,\n",
    "    \"eval_steps\": 500,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"bf16\": True,  # BF16 사용 (A100, H100 등 최신 GPU에서 지원)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11db60ed-4a51-426e-8276-fabcb8fba9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 128\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 데이터셋 로드\n",
    "# CSV 파일인 경우\n",
    "if DATASET_PATH.endswith('.csv'):\n",
    "    dataset = load_dataset('csv', data_files=DATASET_PATH)\n",
    "# JSONL 파일인 경우\n",
    "elif DATASET_PATH.endswith('.jsonl'):\n",
    "    dataset = load_dataset('json', data_files=DATASET_PATH, split='train')\n",
    "else:\n",
    "    raise ValueError(\"지원되지 않는 파일 형식입니다. CSV 또는 JSONL 파일을 사용하세요.\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f359a53b-0b7a-4104-9029-0d48035c4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=hf_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# 5. 양자화 설정 (선택적)\n",
    "# 메모리 제약이 있는 경우 양자화를 사용할 수 있습니다\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4e5a88-16c0-4706-9a2b-ac9e5e970c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. 모델 로드\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    # quantization_config=quantization_config, # instance에 따라서 양자화 지원 여부가 달라집니다. \n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# 7. LoRA 설정\n",
    "# LoRA는 전체 모델을 미세 조정하는 대신 적은 수의 파라미터만 학습하여 효율적인 파인튜닝을 가능하게 합니다\n",
    "peft_config = LoraConfig(\n",
    "    r=16,                     # LoRA 행렬의 랭크\n",
    "    lora_alpha=32,            # LoRA 알파 파라미터\n",
    "    lora_dropout=0.05,        # LoRA 드롭아웃 비율\n",
    "    bias=\"none\",              # 바이어스 파라미터 학습 여부\n",
    "    task_type=\"CAUSAL_LM\",    # 태스크 유형\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],  # 타겟 모듈\n",
    ")\n",
    "\n",
    "# 8. 훈련 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    **training_params,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub=False,  # True로 설정하면 Hugging Face Hub에 모델 업로드\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18643ce2-17e4-4ff5-83bc-e31ceeb900ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6b3f68c-4901-49af-94b4-d84c4553414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 9. 데이터 포맷 확인 및 처리 함수 정의\n",
    "def formatting_func(example):\n",
    "    # 데이터셋 형식에 따라 조정\n",
    "    if \"text\" in example and \"output\" in example:\n",
    "        # text, output 형식\n",
    "        text = example[\"text\"]\n",
    "        output = example[\"output\"]\n",
    "        return f\"{text} {output}\"\n",
    "    elif \"instruction\" in example and \"response\" in example:\n",
    "        # instruction, response 형식\n",
    "        instruction = example[\"instruction\"]\n",
    "        context = example.get(\"context\", \"\")\n",
    "        response = example[\"response\"]\n",
    "\n",
    "        if context:\n",
    "            return f\"<INST>{instruction}\\n\\n{context}</INST> {response}\"\n",
    "        else:\n",
    "            return f\"<INST>{instruction}</INST> {response}\"\n",
    "            \n",
    "    elif \"prompt\" in example and \"completion\" in example:\n",
    "        # instruction, response 형식\n",
    "        instruction = example[\"prompt\"]\n",
    "        context = example.get(\"context\", \"\")\n",
    "        response = example[\"completion\"]\n",
    "\n",
    "        if context:\n",
    "            return f\"<INST>{instruction}\\n\\n{context}</INST> {response}\"\n",
    "        else:\n",
    "            return f\"<INST>{instruction}</INST> {response}\"\n",
    "            \n",
    "    \n",
    "    else:\n",
    "        # 기본 형식 (단일 텍스트)\n",
    "        return example[\"text\"] if \"text\" in example else \"\"\n",
    "\n",
    "# 10. SFT 트레이너 설정\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    # tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"] if \"train\" in dataset else dataset,\n",
    "    \n",
    "    peft_config=peft_config,\n",
    "    formatting_func=formatting_func,\n",
    "    # max_seq_length=max_seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b045c08-3d8a-4cb9-802a-cb1a67485ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 02:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.332800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.910600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=320, training_loss=1.7232888877391814, metrics={'train_runtime': 162.5483, 'train_samples_per_second': 7.875, 'train_steps_per_second': 1.969, 'total_flos': 172351956664320.0, 'train_loss': 1.7232888877391814})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11. 모델 훈련\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6762c9bc-3ee0-48e1-887f-acf15dfc115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 ./llama-3.2-1b-finetuned에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 12. 모델 저장\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "\n",
    "# 13. 토크나이저 저장\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "print(f\"모델이 {OUTPUT_DIR}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd82bb-18a0-4379-a39a-c0becaaa9c57",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb11f01-6df5-43db-afd6-be3694ad98b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bca97c57-220c-4291-9b33-e917a88ddfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(question, model_path, tokenizer):\n",
    "    \"\"\"파인튜닝된 모델을 테스트합니다.\"\"\"\n",
    "    # 모델 로드\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    prompt = f\"<INST>{question}</INST>\"\n",
    "    \n",
    "    # 토큰화\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # 생성\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.5,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            # eos_token_id=128009,          # Llama 3.2 공식 EOS 토큰[1][3]\n",
    "            # pad_token_id=128009,          # 패딩 토큰 통일[4]\n",
    "            repetition_penalty=1.2,       # 반복 문구 억제[3]\n",
    "        )\n",
    "\n",
    "    # 결과 출력\n",
    "    # generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"테스트 결과:\")\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea859b4-8cd3-4b4a-87cf-2533798da07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 결과:\n",
      "<INST>너 이름이 뭐니?.</INST>저는 미니ai라는 이름을 가지고 있어요.\n"
     ]
    }
   ],
   "source": [
    "test_model(\"너 이름이 뭐니?.\", OUTPUT_DIR, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e9e072-ea5b-4593-9f97-298fd79948d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 결과:\n",
      "<INST>너에 대해서 소개 해. 이름이 뭐야?</INST>저는 미니ai라는 이름을 가진 언어 모델입니다.</INST>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(\"너에 대해서 소개 해. 이름이 뭐야?\", OUTPUT_DIR, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd946bc-e4a1-45f6-a9d6-cf1e1ac7b005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822e476-b74c-42ef-83ec-e0373cac0196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141ace6-ed4d-4eea-983e-245387c7fb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f5bc5a-01df-425c-a359-c15f43bb0479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c84ea-1024-491b-b096-2af567efaa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a84fc6-e2d1-4aee-8a0d-2e31ae081f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74574d8-3561-4e3a-bf8a-4617a7e6cbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10282a-e704-40a5-8068-f41c6bf68d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d763ffaa-1ab6-42e9-9c92-6467ba943a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f31f29-7f3e-4e87-8414-b32b2832b6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a67aea-6d76-45df-9982-fbc3534b3726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac2c829-6d3f-4844-89a3-8465d64de725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
